{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from keras.preprocessing.image import array_to_img,img_to_array,load_img\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing import image\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import load_image\n",
    "#import Train_metric_cnn\n",
    "#import Faster_Grad_CAM\n",
    "#import Train_metric_cnn\n",
    "\n",
    "#GPUを使用するためのコード  \n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto(\n",
    "    gpu_options=tf.GPUOptions(\n",
    "        visible_device_list=\"0\", # specify GPU number\n",
    "        allow_growth=True\n",
    "    )\n",
    ")\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "#ここを変えてから動かす\n",
    "#クラスはここに記入\n",
    "#MODEL_NAMEは最後尾に.h5がないとだめ\n",
    "CLASS = 7\n",
    "EPOCH = 4\n",
    "MODEL_NAME = \"model_label_7_100.json\"\n",
    "MODEL_WEIGHTS = \"model_label_7_100.h5\"\n",
    "PATH = \"model/\"\n",
    "\n",
    "\n",
    "\n",
    "#データセットの作成\n",
    "x_train_0 = load_image.load_images(\"images/data/0/\")\n",
    "x_train_1 = load_image.load_images(\"images/data/1/\")\n",
    "x_train_2 = load_image.load_images(\"images/data/2/\")\n",
    "x_train_3 = load_image.load_images(\"images/data/3/\")\n",
    "x_train_4 = load_image.load_images(\"images/data/4/\")\n",
    "x_train_5 = load_image.load_images(\"images/data/5/\")\n",
    "x_train_6 = load_image.load_images(\"images/data/6/\")\n",
    "#x_train_7 = load_images(\"images/data/7/\")\n",
    "print(x_train_0)\n",
    "\n",
    "x_train_0 /= 255\n",
    "x_train_1 /= 255\n",
    "x_train_2 /= 255\n",
    "x_train_3 /= 255\n",
    "x_train_4 /= 255\n",
    "x_train_5 /= 255\n",
    "x_train_6 /= 255\n",
    "#x_train_7 /= 255\n",
    "\n",
    "train_label_0 = np.full(len(x_train_0),0)\n",
    "train_label_1 = np.full(len(x_train_1),1)\n",
    "train_label_2 = np.full(len(x_train_2),2)\n",
    "train_label_3 = np.full(len(x_train_3),3)\n",
    "train_label_4 = np.full(len(x_train_4),4)\n",
    "train_label_5 = np.full(len(x_train_5),5)\n",
    "train_label_6 = np.full(len(x_train_6),6)\n",
    "#train_label_7 = np.full(len(x_train_7),7)\n",
    "\n",
    "\n",
    "x_train_0, x_test_0, y_train_0, y_test_0 = train_test_split(x_train_0, train_label_0, train_size=0.8)\n",
    "x_train_1, x_test_1, y_train_1, y_test_1 = train_test_split(x_train_1, train_label_1, train_size=0.8)\n",
    "x_train_2, x_test_2, y_train_2, y_test_2 = train_test_split(x_train_2, train_label_2, train_size=0.8)\n",
    "x_train_3, x_test_3, y_train_3, y_test_3 = train_test_split(x_train_3, train_label_3, train_size=0.8)\n",
    "x_train_4, x_test_4, y_train_4, y_test_4 = train_test_split(x_train_4, train_label_4, train_size=0.8)\n",
    "x_train_5, x_test_5, y_train_5, y_test_5 = train_test_split(x_train_5, train_label_5, train_size=0.8)\n",
    "x_train_6, x_test_6, y_train_6, y_test_6 = train_test_split(x_train_6, train_label_6, train_size=0.8)\n",
    "#x_train_7, x_test_7, y_train_7, y_test_7 = train_test_split(x_train_7, train_label_7, train_size=0.8)\n",
    "\n",
    "X_train = np.vstack((x_train_0,x_train_1,x_train_2,x_train_3,x_train_4,x_train_5,x_train_6))\n",
    "X_test = np.vstack((x_test_0,x_test_1,x_test_2,x_test_3,x_test_4,x_test_5,x_test_6))\n",
    "y_train = np.hstack((y_train_0,y_train_1,y_train_2,y_train_3,y_train_4,y_train_5,y_train_6))\n",
    "y_test = np.hstack((y_test_0,y_test_1,y_test_2,y_test_3,y_test_4,y_test_5,y_test_6))\n",
    "\n",
    "Y_train = keras.utils.to_categorical(y_train)\n",
    "Y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import vgg19\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Activation\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn import metrics\n",
    "\n",
    "def train_mobileV2(X_train, Y_train, X_test, Y_test, epoch, classes=2, alpha_=0.5):\n",
    "    mobile =vgg19.VGG19(include_top=True,input_shape=(224,224,3),weights='imagenet')\n",
    "    \n",
    "    # 最終層削除\n",
    "    mobile.layers.pop()\n",
    "    v2 = Model(inputs=mobile.input,outputs=mobile.layers[-1].output)\n",
    "\n",
    "    model = build_arcface(X_train, classes, v2)\n",
    "\n",
    "    datagen = ImageDataGenerator(rotation_range=20,\n",
    "                                 width_shift_range=0.2,\n",
    "                                 height_shift_range=0.2,\n",
    "                                 horizontal_flip=True)\n",
    "    \n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    #cnnの学習\n",
    "    hist = model.fit_generator(datagen.flow([X_train, Y_train], Y_train, batch_size=32),\n",
    "                               steps_per_epoch=X_train.shape[0] /32,\n",
    "                               validation_data=([X_test, Y_test], Y_test),\n",
    "                               epochs=epoch, \n",
    "                               verbose=1)\n",
    "\n",
    "    plt.figure()               \n",
    "    plt.plot(hist.history['val_acc'],label=\"val_acc\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return model\n",
    "\n",
    "# mobilenetV2と接合して学習\n",
    "def build_arcface(x, classes, base_model):\n",
    "    #add new layers \n",
    "    hidden = base_model.output\n",
    "    yinput = Input(shape=(classes,)) #ArcFaceで使用\n",
    "    # stock hidden model\n",
    "    c = Arcfacelayer(classes, 30, 0.05)([hidden,yinput]) #outputをクラス数と同じ数に\n",
    "    prediction = Activation('softmax')(c)\n",
    "    model = Model(inputs=[base_model.input, yinput], outputs=prediction)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(lr=0.0001, amsgrad=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "#arcfaceの層\n",
    "class Arcfacelayer(Layer):\n",
    "    # s:softmaxの温度パラメータ, m:margin\n",
    "    def __init__(self, output_dim, s=30, m=0.50, easy_margin=False):\n",
    "        self.output_dim = output_dim\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.easy_margin = easy_margin\n",
    "        super(Arcfacelayer, self).__init__()\n",
    "\n",
    "    # 重みの作成\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(input_shape[0][1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(Arcfacelayer, self).build(input_shape)\n",
    "\n",
    "    # mainの処理 \n",
    "    def call(self, x):\n",
    "        y = x[1]\n",
    "        x_normalize = tf.math.l2_normalize(x[0]) # x = x'/ ||x'||2\n",
    "        k_normalize = tf.math.l2_normalize(self.kernel) # Wj = Wj' / ||Wj'||2\n",
    "\n",
    "        cos_m = K.cos(self.m)\n",
    "        sin_m = K.sin(self.m)\n",
    "        th = K.cos(np.pi - self.m)\n",
    "        mm = K.sin(np.pi - self.m) * self.m\n",
    "\n",
    "        cosine = K.dot(x_normalize, k_normalize) # W.Txの内積\n",
    "        sine = K.sqrt(1.0 - K.square(cosine))\n",
    "\n",
    "        phi = cosine * cos_m - sine * sin_m #cos(θ+m)の加法定理\n",
    "\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine) \n",
    "\n",
    "        else:\n",
    "            phi = tf.where(cosine > th, phi, cosine - mm) \n",
    "\n",
    "        # 正解クラス:cos(θ+m) 他のクラス:cosθ \n",
    "        output = (y * phi) + ((1.0 - y) * cosine) \n",
    "        output *= self.s\n",
    "\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "\n",
    "        return (input_shape[0][0], self.output_dim) #入力[x,y]のためx[0]はinput_shape[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def GradCam(model, x, layer_name, class_, top50):\n",
    "    X = np.expand_dims(x,axis=0)\n",
    "    \n",
    "    # 前処理\n",
    "    target = np.array([0, 1]).reshape((1,-1))\n",
    "    class_idx = class_\n",
    "    class_output = model.output[:, class_idx]\n",
    "    \n",
    "    # 勾配を取得\n",
    "    before = time.time()\n",
    "    conv_output = model.get_layer(layer_name).output   # layer_nameのレイヤーのアウトプット\n",
    "    grads = K.gradients(class_output, conv_output)[0]  # gradients(loss, variables) で、variablesのlossに関しての勾配を返す\n",
    "    gradient_function = K.function([model.input[0],model.input[1]], [conv_output, grads])  # model.inputを入力すると、conv_outputとgradsを出力する関数\n",
    "    \n",
    "    output, grads_val = gradient_function([X, target])\n",
    "    output, grads_val = output[0], grads_val[0]\n",
    "\n",
    "    # 重みを平均化して、レイヤーのアウトプットに乗じる\n",
    "    weights = np.mean(grads_val, axis=(0, 1))\n",
    "    if top50 == True:\n",
    "        label = np.argsort(weights)\n",
    "        cam = np.dot(output[:,:,label[-50:]], weights[label[-50:]])\n",
    "    else:\n",
    "        cam = np.dot(output, weights)\n",
    "\n",
    "    # ヒートマップにして合成\n",
    "    cam = cv2.resize(cam, (x.shape[1], x.shape[0]), cv2.INTER_LINEAR)\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / cam.max()\n",
    "    \n",
    "    jetcam = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)  # モノクロ画像に疑似的に色をつける\n",
    "    jetcam = cv2.cvtColor(jetcam, cv2.COLOR_BGR2RGB)  # 色をRGBに変換\n",
    "    jetcam = (np.float32(jetcam) + x*255 / 2)   # もとの画像に合成\n",
    "\n",
    "    return jetcam, weights, time.time()-before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# compare grad and faster-grad\n",
    "def show_result(model, model_small, layer_name, data, no, kmeans, channel_weight, channel_adress, top50=False):\n",
    "    original, result_grad, result_faster, time0, time1 = [], [], [], [], []\n",
    "    for i in range(5):\n",
    "        original.append(data[no[i]]) \n",
    "        img0, _, time_0 = GradCam(model, data[no[i]], layer_name, 1, top50)\n",
    "        img1, time_1 = predict_faster_gradcam(data[no[i]], model_small, kmeans, channel_weight, channel_adress)\n",
    "        result_grad.append(img0)\n",
    "        result_faster.append(img1)\n",
    "        time0.append(time_0)\n",
    "        time1.append(time_1)\n",
    "\n",
    "    plt.figure(figsize=(15,10))\n",
    "    for i in range(5):\n",
    "        plt.subplot(3,5,i+1)\n",
    "        plt.axis(\"off\")\n",
    "        if i == 0:\n",
    "            plt.title(\"original\")\n",
    "        plt.imshow(original[i])\n",
    "    for i in range(5):\n",
    "        plt.subplot(3,5,i+6)\n",
    "        plt.axis(\"off\")\n",
    "        if i == 0:\n",
    "            time_ = int(np.mean(time1)*1000)\n",
    "            plt.title(\"Faster-Grad-CAM \\n(%d msec)\" % time_)\n",
    "        plt.imshow(array_to_img(result_faster[i]))\n",
    "    for i in range(5):\n",
    "        plt.subplot(3,5,i+11)\n",
    "        plt.axis(\"off\")\n",
    "        if i == 0:\n",
    "            time_ = int(np.mean(time0)*1000)\n",
    "            plt.title(\"Grad-CAM \\n(%d msec)\" % time_)\n",
    "        plt.imshow(array_to_img(result_grad[i]))\n",
    "    plt.show()\n",
    "\n",
    "def train_faster_gradcam(x_normal, x_anomaly, model, clusters=10):\n",
    "    # Arcfaceを削除\n",
    "    model_embed = Model(model.get_layer(index=0).input, [model.layers[-13].get_output_at(-1), model.layers[-4].get_output_at(-1)])\n",
    "\n",
    "    # pa class data\n",
    "    _, vector_normal = model_embed.predict(x_normal)\n",
    "\n",
    "    # gu class data\n",
    "    _, vector_anomaly = model_embed.predict(x_anomaly)# shape[(len(x), 3, 3, 480), (len(x), 1280)]\n",
    "\n",
    "    # k-means\n",
    "    kmeans = KMeans(n_clusters=clusters, random_state=0).fit(vector_anomaly)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # channel database\n",
    "    channel_weight, channel_adress = [], []\n",
    "    temp_weight = np.zeros((clusters, 480))# 480=\"block_16_expand_relu\".output\n",
    "    print(\"Making Database...\")\n",
    "    for i in range(len(labels)):\n",
    "        # x_anomalyについて一個ずつ重みを加算していく\n",
    "        _, weight, _ = GradCam(model, x_anomaly[i], \"block_16_expand_relu\", 1, False)\n",
    "        temp_weight[labels[i]] += weight #要確認\n",
    "        print(i+1,\"/\",len(labels))\n",
    "\n",
    "    for i in range(clusters):\n",
    "        number = np.where(labels == i, 1, 0) #クラスタ内の個数\n",
    "        average_weight = temp_weight[i] / np.sum(number) #重みの平均\n",
    "        weight_adress = np.argsort(average_weight)\n",
    "        channel_adress.append(weight_adress[-50:])\n",
    "        channel_weight.append(average_weight[weight_adress[-50:]])\n",
    "\n",
    "    return model_embed, kmeans, np.array(channel_weight), np.array(channel_adress), vector_normal\n",
    "\n",
    "def predict_faster_gradcam(x, model, kmeans, channel_weight, channel_adress):\n",
    "    before = time.time()\n",
    "    channel_out, vector = model.predict(np.expand_dims(x, axis=0))\n",
    "    channel_out = channel_out[0]\n",
    "    cluster_no = kmeans.predict(vector)\n",
    "    # レイヤーのアウトプットに乗じる\n",
    "    cam = np.dot(channel_out[:,:,channel_adress[cluster_no][0]], channel_weight[cluster_no][0])\n",
    "\n",
    "    # ヒートマップにして合成\n",
    "    cam = cv2.resize(cam, (x.shape[1], x.shape[0]), cv2.INTER_LINEAR)\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / cam.max()\n",
    "    \n",
    "    jetcam = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)  # モノクロ画像に疑似的に色をつける\n",
    "    jetcam = cv2.cvtColor(jetcam, cv2.COLOR_BGR2RGB)  # 色をRGBに変換\n",
    "    jetcam = (np.float32(jetcam) + x*255 / 2)   # もとの画像に合成\n",
    "\n",
    "    return jetcam, time.time()-before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_mobileV2(X_train, Y_train, X_test, Y_test, EPOCH, classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
