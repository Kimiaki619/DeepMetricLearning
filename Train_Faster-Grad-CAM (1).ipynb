{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nM8AuzWISNMF"
   },
   "source": [
    "#jenken data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/karaage0703/janken_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5mfi5-Ty92wV"
   },
   "source": [
    "Note that below code is done on Colaboratory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22670,
     "status": "ok",
     "timestamp": 1584334339361,
     "user": {
      "displayName": "shinmura shinmura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghsna5ynBrXNZax3CloVEJ1JQExQDfj4DKZ93SCNQ=s64",
      "userId": "02985854947085672136"
     },
     "user_tz": -540
    },
    "id": "Yju4XS6q0MU6",
    "outputId": "4f6abc98-0017-4138-8901-7ad0e056193e"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob, cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from keras.preprocessing.image import array_to_img,img_to_array,load_img\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto(\n",
    "    gpu_options=tf.GPUOptions(\n",
    "        visible_device_list=\"1\", # specify GPU number\n",
    "        allow_growth=True\n",
    "    )\n",
    ")\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "def load_images(path):\n",
    "    result_img = []\n",
    "    file_name = glob.glob(path + \"*\")\n",
    "    for name in file_name:\n",
    "        img = Image.open(name)\n",
    "        img = img_to_array(img)\n",
    "        img = cv2.resize(img,(224, 224))\n",
    "        result_img.append(img)\n",
    "    return np.array(result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "gu = load_images(\"janken_dataset/gu/\")\n",
    "pa = load_images(\"janken_dataset/pa/\")\n",
    "gu_label = np.ones(len(gu))\n",
    "pa_label = np.zeros(len(pa))\n",
    "\n",
    "gu /= 255\n",
    "pa /= 255\n",
    "\n",
    "gu_train, gu_test, y_gu_train, y_gu_test = train_test_split(gu, gu_label, train_size=0.8)\n",
    "pa_train, pa_test, y_pa_train, y_pa_test = train_test_split(pa, pa_label, train_size=0.8)\n",
    "\n",
    "X_train = np.vstack((gu_train, pa_train))\n",
    "X_test = np.vstack((gu_test, pa_test))\n",
    "y_train = np.hstack((y_gu_train, y_pa_train))\n",
    "y_test = np.hstack((y_gu_test, y_pa_test))\n",
    "\n",
    "Y_train = keras.utils.to_categorical(y_train)\n",
    "Y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22971,
     "status": "ok",
     "timestamp": 1584334339676,
     "user": {
      "displayName": "shinmura shinmura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghsna5ynBrXNZax3CloVEJ1JQExQDfj4DKZ93SCNQ=s64",
      "userId": "02985854947085672136"
     },
     "user_tz": -540
    },
    "id": "UkLsEDaWPDOk",
    "outputId": "135e7423-ad98-4e3f-c72e-4e1be581c871"
   },
   "outputs": [],
   "source": [
    "#dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from keras.preprocessing.image import array_to_img,img_to_array,load_img\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "x_train_0 = load_images(\"images/train/0/\")\n",
    "x_train_1 = load_images(\"images/train/1/\")\n",
    "x_train_2 = load_images(\"images/train/2/\")\n",
    "x_train_3 = load_images(\"images/train/3/\")\n",
    "\n",
    "#print(x_train_0)\n",
    "\n",
    "y_train_0 = np.full(len(x_train_0),0)\n",
    "y_train_1 = np.full(len(x_train_1),1)\n",
    "y_train_2 = np.full(len(x_train_2),2)\n",
    "y_train_3 = np.full(len(x_train_3),3)\n",
    "\n",
    "x_train_0 /= 255\n",
    "x_train_1 /= 255\n",
    "x_train_2 /= 255\n",
    "x_train_3 /= 255\n",
    "\n",
    "X_train = np.vstack((x_train_0,x_train_1,x_train_2,x_train_3))#x_train_1,x_train_2,x_train_3))\n",
    "y_train = np.hstack((y_train_0,y_train_2,y_train_3,y_train_3))#y_train_1,y_train_2,y_train_3))\n",
    "\n",
    "x_test_0 = load_images(\"images/test/0/\")\n",
    "x_test_1 = load_images(\"images/test/1/\")\n",
    "x_test_2 = load_images(\"images/test/2/\")\n",
    "x_test_3 = load_images(\"images/test/3/\")\n",
    "\n",
    "y_test_0 = np.full(len(x_test_0),0)\n",
    "y_test_1 = np.full(len(x_test_1),1)\n",
    "y_test_2 = np.full(len(x_test_2),2)\n",
    "y_test_3 = np.full(len(x_test_3),3)\n",
    "\n",
    "\n",
    "x_test_0 /= 255\n",
    "x_test_1 /= 255\n",
    "x_test_2 /= 255\n",
    "x_test_3 /= 255\n",
    "\n",
    "X_test = np.vstack((x_test_0,x_test_1,x_test_2,x_test_3))\n",
    "y_test = np.hstack((y_test_0,y_test_1,y_test_2,y_test_3))\n",
    "\n",
    "Y_train = keras.utils.to_categorical(y_train)\n",
    "Y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from keras.preprocessing.image import array_to_img,img_to_array,load_img\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "x_train_0 = load_images(\"images/train/0/\")\n",
    "x_train_1 = load_images(\"images/train/1/\")\n",
    "x_train_2 = load_images(\"images/train/2/\")\n",
    "x_train_3 = load_images(\"images/train/3/\")\n",
    "x_train_4 = load_images(\"images/train/4/\")\n",
    "x_train_5 = load_images(\"images/train/5/\")\n",
    "x_train_6 = load_images(\"images/train/6/\")\n",
    "#print(x_train_0)\n",
    "\n",
    "y_train_0 = np.full(len(x_train_0),0)\n",
    "y_train_1 = np.full(len(x_train_1),1)\n",
    "y_train_2 = np.full(len(x_train_2),2)\n",
    "y_train_3 = np.full(len(x_train_3),3)\n",
    "y_train_4 = np.full(len(x_train_4),4)\n",
    "y_train_5 = np.full(len(x_train_5),5)\n",
    "y_train_6 = np.full(len(x_train_6),6)\n",
    "\n",
    "x_train_0 /= 255\n",
    "x_train_1 /= 255\n",
    "x_train_2 /= 255\n",
    "x_train_3 /= 255\n",
    "x_train_4 /= 255\n",
    "x_train_5 /= 255\n",
    "x_train_6 /= 255\n",
    "\n",
    "X_train = np.vstack((x_train_0,x_train_1,x_train_2,x_train_3,x_train_4,x_train_5,x_train_6))\n",
    "y_train = np.hstack((y_train_0,y_train_1,y_train_2,y_train_3,y_train_4,y_train_5,y_train_6))\n",
    "\n",
    "x_test_0 = load_images(\"images/test/0/\")\n",
    "x_test_1 = load_images(\"images/test/1/\")\n",
    "x_test_2 = load_images(\"images/test/2/\")\n",
    "x_test_3 = load_images(\"images/test/3/\")\n",
    "x_test_4 = load_images(\"images/test/4/\")\n",
    "x_test_5 = load_images(\"images/test/5/\")\n",
    "x_test_6 = load_images(\"images/test/6/\")\n",
    "\n",
    "y_test_0 = np.full(len(x_test_0),0)\n",
    "y_test_1 = np.full(len(x_test_1),1)\n",
    "y_test_2 = np.full(len(x_test_2),2)\n",
    "y_test_3 = np.full(len(x_test_3),3)\n",
    "y_test_4 = np.full(len(x_test_4),4)\n",
    "y_test_5 = np.full(len(x_test_5),5)\n",
    "y_test_6 = np.full(len(x_test_6),6)\n",
    "\n",
    "\n",
    "x_test_0 /= 255\n",
    "x_test_1 /= 255\n",
    "x_test_2 /= 255\n",
    "x_test_3 /= 255\n",
    "x_test_4 /= 255\n",
    "x_test_5 /= 255\n",
    "x_test_6 /= 255\n",
    "\n",
    "X_test = np.vstack((x_test_0,x_test_1,x_test_2,x_test_3,x_test_4,x_test_5,x_test_6))\n",
    "y_test = np.hstack((y_test_0,y_test_1,y_test_2,y_test_3,y_test_4,y_test_5,y_test_6))\n",
    "\n",
    "Y_train = keras.utils.to_categorical(y_train)\n",
    "Y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s9yK71YhCyS4"
   },
   "source": [
    "###(Fig show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-WhMl2fCySg"
   },
   "outputs": [],
   "source": [
    "def plot_fig(fig1, fig2, fig3, fig4):\n",
    "    plt.figure(figsize=(15,60))\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.imshow(fig1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"0\")\n",
    "\n",
    "    plt.subplot(1,4,2)\n",
    "    plt.imshow(fig2)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"1\")\n",
    "\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.imshow(fig3)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"2\")\n",
    "\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.imshow(fig4)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"3\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fig(x_train_0[0],x_train_1[0],x_train_2[0],x_train_3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23893,
     "status": "ok",
     "timestamp": 1584334341215,
     "user": {
      "displayName": "shinmura shinmura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghsna5ynBrXNZax3CloVEJ1JQExQDfj4DKZ93SCNQ=s64",
      "userId": "02985854947085672136"
     },
     "user_tz": -540
    },
    "id": "w9UxwT-OCySK",
    "outputId": "7cca5d93-aa6b-4573-f04d-b209074ffea3"
   },
   "outputs": [],
   "source": [
    "plot_fig(x_test_0[0],x_test_1[0],x_test_2[0],x_test_3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EdOyuY5zxbe2"
   },
   "source": [
    "#CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rp2Qy8HiaHA7"
   },
   "source": [
    "##MobileNet V2 with ArcFace(2 classes)\n",
    "(Of course 3 classes is possible.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gjuc0Q3kaJmI"
   },
   "outputs": [],
   "source": [
    "from keras.applications import vgg19\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Activation\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn import metrics\n",
    "\n",
    "def train_mobileV2(X_train, Y_train, X_test, Y_test, epoch, classes=4, alpha_=0.5):\n",
    "    mobile = vgg19.VGG19(include_top=True, input_shape=X_train.shape[1:],weights='imagenet')\n",
    "    \n",
    "    # 最終層削除\n",
    "    mobile.layers.pop()\n",
    "    v2 = Model(inputs=mobile.input,outputs=mobile.layers[-1].output)\n",
    "\n",
    "    model = build_arcface(X_train, classes, v2)\n",
    "\n",
    "    datagen = ImageDataGenerator(rotation_range=20,\n",
    "                                 width_shift_range=0.2,\n",
    "                                 height_shift_range=0.2,\n",
    "                                 horizontal_flip=True)\n",
    "    model.summary()\n",
    "    \n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    #cnnの学習\n",
    "    hist = model.fit_generator(datagen.flow([X_train, Y_train], Y_train, batch_size=32),\n",
    "                               steps_per_epoch=X_train.shape[0] /32,\n",
    "                               validation_data=([X_test, Y_test], Y_test),\n",
    "                               epochs=epoch, \n",
    "                               verbose=1)\n",
    "\n",
    "    plt.figure()               \n",
    "    plt.plot(hist.history['val_acc'],label=\"val_acc\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return model\n",
    "\n",
    "# mobilenetV2と接合して学習\n",
    "def build_arcface(x, classes, base_model):\n",
    "    #add new layers \n",
    "    hidden = base_model.output\n",
    "    yinput = Input(shape=(classes,)) #ArcFaceで使用\n",
    "    print(hidden,yinput)\n",
    "    # stock hidden model\n",
    "    c = Arcfacelayer(classes, 30, 0.05)([hidden,yinput]) #outputをクラス数と同じ数に\n",
    "    prediction = Activation('softmax')(c)\n",
    "    model = Model(inputs=[base_model.input, yinput], outputs=prediction)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(lr=0.0001, amsgrad=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "#arcfaceの層\n",
    "class Arcfacelayer(Layer):\n",
    "    # s:softmaxの温度パラメータ, m:margin\n",
    "    def __init__(self, output_dim, s=30, m=0.50, easy_margin=False):\n",
    "        self.output_dim = output_dim\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.easy_margin = easy_margin\n",
    "        super(Arcfacelayer, self).__init__()\n",
    "\n",
    "    # 重みの作成\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(input_shape[0][1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(Arcfacelayer, self).build(input_shape)\n",
    "\n",
    "    # mainの処理 \n",
    "    def call(self, x):\n",
    "        y = x[1]\n",
    "        x_normalize = tf.math.l2_normalize(x[0]) # x = x'/ ||x'||2\n",
    "        k_normalize = tf.math.l2_normalize(self.kernel) # Wj = Wj' / ||Wj'||2\n",
    "\n",
    "        cos_m = K.cos(self.m)\n",
    "        sin_m = K.sin(self.m)\n",
    "        th = K.cos(np.pi - self.m)\n",
    "        mm = K.sin(np.pi - self.m) * self.m\n",
    "\n",
    "        cosine = K.dot(x_normalize, k_normalize) # W.Txの内積\n",
    "        sine = K.sqrt(1.0 - K.square(cosine))\n",
    "\n",
    "        phi = cosine * cos_m - sine * sin_m #cos(θ+m)の加法定理\n",
    "\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine) \n",
    "\n",
    "        else:\n",
    "            phi = tf.where(cosine > th, phi, cosine - mm) \n",
    "\n",
    "        # 正解クラス:cos(θ+m) 他のクラス:cosθ \n",
    "        output = (y * phi) + ((1.0 - y) * cosine) \n",
    "        output *= self.s\n",
    "\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "\n",
    "        return (input_shape[0][0], self.output_dim) #入力[x,y]のためx[0]はinput_shape[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kqDt6L0XeDP-"
   },
   "source": [
    "##Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3z6wEJvpkjX0"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def GradCam(model, x, layer_name, class_, top50):\n",
    "    X = np.expand_dims(x,axis=0)\n",
    "    \n",
    "    # 前処理\n",
    "    target = np.array([0, 1,2,3]).reshape((1,-1))\n",
    "    class_idx = class_\n",
    "    class_output = model.output[:, class_idx]\n",
    "    \n",
    "    # 勾配を取得\n",
    "    before = time.time()\n",
    "    conv_output = model.get_layer(layer_name).output   # layer_nameのレイヤーのアウトプット\n",
    "    grads = K.gradients(class_output, conv_output)[0]  # gradients(loss, variables) で、variablesのlossに関しての勾配を返す\n",
    "    gradient_function = K.function([model.input[0],model.input[1]], [conv_output, grads])  # model.inputを入力すると、conv_outputとgradsを出力する関数\n",
    "    \n",
    "    output, grads_val = gradient_function([X, target])\n",
    "    output, grads_val = output[0], grads_val[0]\n",
    "\n",
    "    # 重みを平均化して、レイヤーのアウトプットに乗じる\n",
    "    weights = np.mean(grads_val, axis=(0, 1))\n",
    "    if top50 == True:\n",
    "        label = np.argsort(weights)\n",
    "        cam = np.dot(output[:,:,label[-50:]], weights[label[-50:]])\n",
    "    else:\n",
    "        cam = np.dot(output, weights)\n",
    "\n",
    "    # ヒートマップにして合成\n",
    "    cam = cv2.resize(cam, (x.shape[1], x.shape[0]), cv2.INTER_LINEAR)\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / cam.max()\n",
    "    \n",
    "    jetcam = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)  # モノクロ画像に疑似的に色をつける\n",
    "    jetcam = cv2.cvtColor(jetcam, cv2.COLOR_BGR2RGB)  # 色をRGBに変換\n",
    "    jetcam = (np.float32(jetcam) + x*255 / 2)   # もとの画像に合成\n",
    "\n",
    "    return jetcam, weights, time.time()-before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fmnQROAek531"
   },
   "source": [
    "##Faster-Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ys0LqscUeF3B"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# compare grad and faster-grad\n",
    "def show_result(model, model_small, layer_name, data, no, kmeans, channel_weight, channel_adress, top50=False):\n",
    "    original, result_grad, result_faster, time0, time1 = [], [], [], [], []\n",
    "    for i in range(5):\n",
    "        original.append(data[no[i]]) \n",
    "        img0, _, time_0 = GradCam(model, data[no[i]], layer_name, 1, top50)\n",
    "        img1, time_1 = predict_faster_gradcam(data[no[i]], model_small, kmeans, channel_weight, channel_adress)\n",
    "        result_grad.append(img0)\n",
    "        result_faster.append(img1)\n",
    "        time0.append(time_0)\n",
    "        time1.append(time_1)\n",
    "\n",
    "    plt.figure(figsize=(15,10))\n",
    "    for i in range(5):\n",
    "        plt.subplot(3,5,i+1)\n",
    "        plt.axis(\"off\")\n",
    "        if i == 0:\n",
    "            plt.title(\"original\")\n",
    "        plt.imshow(original[i])\n",
    "    for i in range(5):\n",
    "        plt.subplot(3,5,i+6)\n",
    "        plt.axis(\"off\")\n",
    "        if i == 0:\n",
    "            time_ = int(np.mean(time1)*1000)\n",
    "            plt.title(\"Faster-Grad-CAM \\n(%d msec)\" % time_)\n",
    "        plt.imshow(array_to_img(result_faster[i]))\n",
    "    for i in range(5):\n",
    "        plt.subplot(3,5,i+11)\n",
    "        plt.axis(\"off\")\n",
    "        if i == 0:\n",
    "            time_ = int(np.mean(time0)*1000)\n",
    "            plt.title(\"Grad-CAM \\n(%d msec)\" % time_)\n",
    "        plt.imshow(array_to_img(result_grad[i]))\n",
    "    plt.show()\n",
    "\n",
    "def train_faster_gradcam(x_normal0,x_normal1,x_normal2, x_anomaly, model, clusters=10):\n",
    "    # Arcfaceを削除\n",
    "    model_embed = Model(model.get_layer(index=0).input, [model.layers[-13].get_output_at(-1), model.layers[-4].get_output_at(-1)])\n",
    "\n",
    "    # pa class data\n",
    "    _, vector_normal = model_embed.predict(x_normal0)\n",
    "    _, vector_normal1 = model_embed.predict(x_normal1)\n",
    "    _, vector_normal2 = model_embed.predict(x_normal2)\n",
    "    vector_normal += vector_normal1+vector_normal2\n",
    "    \n",
    "    # gu class data\n",
    "    _, vector_anomaly = model_embed.predict(x_anomaly)# shape[(len(x), 3, 3, 480), (len(x), 1280)]\n",
    "    print(vector_anomaly)\n",
    "    # k-means\n",
    "    kmeans = KMeans(n_clusters=clusters, random_state=0).fit(vector_anomaly)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # channel database\n",
    "    channel_weight, channel_adress = [], []\n",
    "    temp_weight = np.zeros((clusters, 512))# 480=\"block_16_expand_relu\".output\n",
    "    print(\"Making Database...\")\n",
    "    for i in range(len(labels)):\n",
    "        # x_anomalyについて一個ずつ重みを加算していく\n",
    "        _, weight, _ = GradCam(model, x_anomaly[i], \"block5_conv4\", 1, False)\n",
    "        temp_weight[labels[i]] += weight #要確認\n",
    "        print(i+1,\"/\",len(labels))\n",
    "\n",
    "    for i in range(clusters):\n",
    "        number = np.where(labels == i, 1, 0) #クラスタ内の個数\n",
    "        average_weight = temp_weight[i] / np.sum(number) #重みの平均\n",
    "        weight_adress = np.argsort(average_weight)\n",
    "        channel_adress.append(weight_adress[-50:])\n",
    "        channel_weight.append(average_weight[weight_adress[-50:]])\n",
    "\n",
    "    return model_embed, kmeans, np.array(channel_weight), np.array(channel_adress), vector_normal\n",
    "\n",
    "def predict_faster_gradcam(x, model, kmeans, channel_weight, channel_adress):\n",
    "    before = time.time()\n",
    "    channel_out, vector = model.predict(np.expand_dims(x, axis=0))\n",
    "    channel_out = channel_out[0]\n",
    "    cluster_no = kmeans.predict(vector)\n",
    "    # レイヤーのアウトプットに乗じる\n",
    "    cam = np.dot(channel_out[:,:,channel_adress[cluster_no][0]], channel_weight[cluster_no][0])\n",
    "\n",
    "    # ヒートマップにして合成\n",
    "    cam = cv2.resize(cam, (x.shape[1], x.shape[0]), cv2.INTER_LINEAR)\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / cam.max()\n",
    "    \n",
    "    jetcam = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)  # モノクロ画像に疑似的に色をつける\n",
    "    jetcam = cv2.cvtColor(jetcam, cv2.COLOR_BGR2RGB)  # 色をRGBに変換\n",
    "    jetcam = (np.float32(jetcam) + x*255 / 2)   # もとの画像に合成\n",
    "\n",
    "    return jetcam, time.time()-before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JFTmo48MXpmK"
   },
   "source": [
    "#Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5WEGJxr2OMjx"
   },
   "source": [
    "##ArcFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43675,
     "status": "ok",
     "timestamp": 1584334426079,
     "user": {
      "displayName": "shinmura shinmura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghsna5ynBrXNZax3CloVEJ1JQExQDfj4DKZ93SCNQ=s64",
      "userId": "02985854947085672136"
     },
     "user_tz": -540
    },
    "id": "6AMk134UHn5o",
    "outputId": "7061dcee-0b49-4cf8-83eb-0adc7705741a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = train_mobileV2(X_train, Y_train, X_test, Y_test, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D_surtdGri5d"
   },
   "source": [
    "##Faster-Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 74035,
     "status": "ok",
     "timestamp": 1584334519812,
     "user": {
      "displayName": "shinmura shinmura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghsna5ynBrXNZax3CloVEJ1JQExQDfj4DKZ93SCNQ=s64",
      "userId": "02985854947085672136"
     },
     "user_tz": -540
    },
    "id": "u1aZVu5diXea",
    "outputId": "9533d927-460d-4dc5-d56d-8508fc4e1a21",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_grad, kmeans, channel_weight, channel_adress, vector_normal = train_faster_gradcam(x_train_0,x_train_1,x_train_2, x_train_3, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 84429,
     "status": "ok",
     "timestamp": 1584334532404,
     "user": {
      "displayName": "shinmura shinmura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghsna5ynBrXNZax3CloVEJ1JQExQDfj4DKZ93SCNQ=s64",
      "userId": "02985854947085672136"
     },
     "user_tz": -540
    },
    "id": "OF0y0ppbZj21",
    "outputId": "7c0947e4-236b-4dce-f41c-398879fa1f32"
   },
   "outputs": [],
   "source": [
    "show_result(model, model_grad, \"block5_conv4\", x_test_3, [0,12,5,7,8], kmeans, channel_weight, channel_adress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqAVQufbXwyt"
   },
   "source": [
    "#Save output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "path = \"model/\"\n",
    "model_json = model_grad.to_json()\n",
    "open(path+'model.json', 'w').write(model_json)\n",
    "model_grad.save_weights(path + 'weights_4_20.h5')\n",
    "joblib.dump(kmeans, path + 'k-means_4_20.pkl.cmp', compress=True)\n",
    "np.savetxt(path + \"channel_weight_4_20.csv\", channel_weight, delimiter=\",\")\n",
    "np.savetxt(path + \"channel_adress_4_20.csv\", channel_adress, delimiter=\",\")\n",
    "np.savetxt(path + \"vector_3_4_20.csv\", vector_normal, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(path + \"model_4_20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XG8nqIH1sU5J"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VpKuOgDjX4Ec"
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "path = \"model/\"\n",
    "model_json = model_grad.to_json()\n",
    "open(path + 'model.json', 'w').write(model_json)\n",
    "model_grad.save_weights(path + 'weights.h5')\n",
    "\n",
    "joblib.dump(kmeans, path + 'k-means.pkl.cmp', compress=True)\n",
    "\n",
    "np.savetxt(path + \"channel_weight.csv\", channel_weight, delimiter=\",\")\n",
    "np.savetxt(path + \"channel_adress.csv\", channel_adress, delimiter=\",\")\n",
    "np.savetxt(path + \"vector_pa.csv\", vector_normal, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "waM01x_528Oy"
   },
   "source": [
    " Finally transfer output files to your RaspberryPi or PC."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Train_Faster-Grad-CAM.ipynb のコピー",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
